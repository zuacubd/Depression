{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import collections\n",
    "import csv\n",
    "import argparse\n",
    "import random\n",
    "import re\n",
    "import emoji\n",
    "import pickle\n",
    "\n",
    "import xml.etree.ElementTree as et\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from load import *\n",
    "\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from transformers import AdamW\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "#from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "#                              TensorDataset)\n",
    "# pass the pre-trained BERT to our define architecture\n",
    "\n",
    "# push the model to GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bert pre-trained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "#load the bert tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the architecture\n",
    "class BERT_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, bert):\n",
    "      \n",
    "      super(BERT_Arch, self).__init__()\n",
    "\n",
    "      self.bert = bert \n",
    "      \n",
    "      # dropout layer\n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      \n",
    "      # relu activation function\n",
    "      self.relu =  nn.ReLU()\n",
    "\n",
    "      # dense layer 1\n",
    "      self.fc1 = nn.Linear(768,512)\n",
    "      \n",
    "      # dense layer 2 (Output layer)\n",
    "      self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "      #softmax activation function\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "      #pass the inputs to the model  \n",
    "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "      #print (cls_hs)\n",
    "      x = self.fc1(cls_hs)\n",
    "\n",
    "      x = self.relu(x)\n",
    "\n",
    "      x = self.dropout(x)\n",
    "\n",
    "      # output layer\n",
    "      x = self.fc2(x)\n",
    "      \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5)          # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Actually, there isn't anything reasonable that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>if a foreign terrorist had committed this atta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>worth a dismissive news segment?. . what are y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Why do you think the nose is fake?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>its not uncommon for there to be 10+ or even 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                              texts\n",
       "0       0  Actually, there isn't anything reasonable that...\n",
       "1       0  if a foreign terrorist had committed this atta...\n",
       "2       0  worth a dismissive news segment?. . what are y...\n",
       "3       0                 Why do you think the nose is fake?\n",
       "4       0  its not uncommon for there to be 10+ or even 3..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=2017\n",
    "processed_train_dir = \"/projets/sig/mullah/nlp/depression/data/processed/\"+str(year)+\"/train/\"\n",
    "processed_test_dir = \"/projets/sig/mullah/nlp/depression/data/processed/\"+str(year)+\"/test/\"\n",
    "models_dir = \"/projets/sig/mullah/nlp/depression/models/\"+str(year)+\"/bert\"\n",
    "df = pd.read_csv(os.path.join(processed_train_dir, \"train_texts\"))\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168588\n",
      "125497    I'm not sure how you ended up there. My link w...\n",
      "93754     That's the excuse. When CU was snubbed they lo...\n",
      "142815    This is what you get from the GOP.  Care about...\n",
      "16070                                              *shhhhh*\n",
      "208644          The scissor scene at the end is what got me\n",
      "Name: texts, dtype: object\n",
      "42148\n",
      "55786     http://www.reactiongifs.com/wp-content/uploads...\n",
      "152872                                            A Twinkie\n",
      "146112    Yeah.. i'm thinking I may take note of the pla...\n",
      "112701    I do repost it with Ars Technica article today...\n",
      "41041         Tried to pretend I was straight and cis. Lel.\n",
      "Name: texts, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, val_text, train_labels, val_labels = train_test_split(df['texts'], df['labels'], \n",
    "                                                                    random_state=42, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=df['labels'])\n",
    "print (len(train_text))\n",
    "print (train_text.head())\n",
    "print (len(val_text))\n",
    "print (val_text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 128,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 128,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "#tokens_test = tokenizer.batch_encode_plus(\n",
    "#    test_text.tolist(),\n",
    "#    max_length = 25,\n",
    "#    pad_to_max_length=True,\n",
    "#    truncation=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert lists to tensors\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "#test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "#test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "#test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.57687017 3.75223681]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/sig/mullah/.conda/envs/e36t11/lib/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0 1], y=125497    0\n",
      "93754     0\n",
      "142815    0\n",
      "16070     0\n",
      "208644    1\n",
      "         ..\n",
      "92994     0\n",
      "94349     0\n",
      "132760    0\n",
      "186933    1\n",
      "165545    0\n",
      "Name: labels, Length: 168588, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#compute the class weights\n",
    "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "print(\"Class Weights:\",class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch]\n",
    " \n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  # compute the training loss of the epoch\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  # deactivate dropout layers\n",
    "  model.eval()\n",
    "\n",
    "  total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "  # empty list to save the model predictions\n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      #elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "      # Report progress.\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "    # push the batch to gpu\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      # model predictions\n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      # compute the validation loss between actual and predicted values\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  # compute the validation loss of the epoch\n",
    "  avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 5\n",
      "tensor([[-0.7860, -0.3083, -0.9556,  ..., -0.9619, -0.5049,  0.5935],\n",
      "        [-0.5173, -0.3954, -0.8087,  ..., -0.5137, -0.5104,  0.6033],\n",
      "        [-0.8328, -0.3096, -0.3384,  ..., -0.0941, -0.6280,  0.8747],\n",
      "        ...,\n",
      "        [-0.6716, -0.1517,  0.1049,  ...,  0.1008, -0.4106,  0.7473],\n",
      "        [-0.8656, -0.4745, -0.9330,  ..., -0.8457, -0.7078,  0.9234],\n",
      "        [-0.8664, -0.4904, -0.9108,  ..., -0.7712, -0.6813,  0.9069]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7638, -0.5102, -0.8891,  ..., -0.5920, -0.5658,  0.6872],\n",
      "        [-0.8473, -0.4133, -0.8932,  ..., -0.7572, -0.6269,  0.8038],\n",
      "        [-0.7674, -0.2439, -0.4734,  ..., -0.5775, -0.5418,  0.8815],\n",
      "        ...,\n",
      "        [-0.8013, -0.7055, -0.9888,  ..., -0.9198, -0.7133,  0.8704],\n",
      "        [-0.8094, -0.3682, -0.6495,  ..., -0.5362, -0.4881,  0.8907],\n",
      "        [-0.7498, -0.2861, -0.6123,  ..., -0.5247, -0.6364,  0.8418]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8369, -0.2922, -0.5192,  ..., -0.3759, -0.5726,  0.8296],\n",
      "        [-0.6815, -0.3118, -0.9163,  ..., -0.7749, -0.5619,  0.4043],\n",
      "        [-0.8810, -0.4874, -0.8922,  ..., -0.4319, -0.6923,  0.8891],\n",
      "        ...,\n",
      "        [-0.9006, -0.5491, -0.8709,  ..., -0.6283, -0.7815,  0.8084],\n",
      "        [-0.6216, -0.0836,  0.5803,  ...,  0.5169, -0.4617,  0.6417],\n",
      "        [-0.9069, -0.3704, -0.7317,  ..., -0.5094, -0.7368,  0.9177]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7580, -0.4113, -0.9359,  ..., -0.8463, -0.5924,  0.8355],\n",
      "        [-0.7484, -0.4209, -0.9452,  ..., -0.7910, -0.6067,  0.6285],\n",
      "        [-0.8039, -0.2602,  0.5618,  ...,  0.4294, -0.4761,  0.8602],\n",
      "        ...,\n",
      "        [-0.6599, -0.3201, -0.8704,  ..., -0.7349, -0.6037,  0.7136],\n",
      "        [-0.6176, -0.5586, -0.8513,  ..., -0.7518, -0.6788,  0.6802],\n",
      "        [-0.8397, -0.5233, -0.9769,  ..., -0.9102, -0.6099,  0.8951]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8677, -0.3926, -0.9301,  ..., -0.7940, -0.6161,  0.8542],\n",
      "        [-0.7127, -0.1475,  0.8443,  ...,  0.4782, -0.4629,  0.6877],\n",
      "        [-0.7875, -0.4703, -0.9905,  ..., -0.9505, -0.6263,  0.6934],\n",
      "        ...,\n",
      "        [-0.7495, -0.1501, -0.6877,  ..., -0.3750, -0.5159,  0.8282],\n",
      "        [-0.9297, -0.5458, -0.9399,  ..., -0.7617, -0.7358,  0.9250],\n",
      "        [-0.8467, -0.5921, -0.9525,  ..., -0.8006, -0.7193,  0.8304]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8201, -0.2605, -0.6529,  ..., -0.4767, -0.6332,  0.8698],\n",
      "        [-0.9208, -0.6368, -0.9681,  ..., -0.8556, -0.7559,  0.8778],\n",
      "        [-0.7794, -0.4465, -0.8738,  ..., -0.4113, -0.6747,  0.7558],\n",
      "        ...,\n",
      "        [-0.8198, -0.4974, -0.9681,  ..., -0.9324, -0.6099,  0.8602],\n",
      "        [-0.8095, -0.3160, -0.6087,  ..., -0.6150, -0.5179,  0.8434],\n",
      "        [-0.7598, -0.2008, -0.4544,  ..., -0.3333, -0.5117,  0.8838]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6731, -0.4545, -0.9523,  ..., -0.8994, -0.6832,  0.7501],\n",
      "        [-0.6855, -0.2276, -0.3942,  ..., -0.0564, -0.4585,  0.8413],\n",
      "        [-0.7765, -0.1309,  0.1733,  ...,  0.0462, -0.5124,  0.7994],\n",
      "        ...,\n",
      "        [-0.7134, -0.2329, -0.7503,  ..., -0.5938, -0.4954,  0.7823],\n",
      "        [-0.7795, -0.3758, -0.6682,  ..., -0.5432, -0.6049,  0.8377],\n",
      "        [-0.5821, -0.4866, -0.9358,  ..., -0.9307, -0.5282,  0.7730]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6484, -0.2401, -0.8989,  ..., -0.7073, -0.5557,  0.6362],\n",
      "        [-0.8710, -0.6084, -0.9858,  ..., -0.9502, -0.8277,  0.9036],\n",
      "        [-0.8044, -0.3226, -0.4557,  ...,  0.0636, -0.5815,  0.8625],\n",
      "        ...,\n",
      "        [-0.4447, -0.1994, -0.5251,  ..., -0.4664, -0.4424,  0.6021],\n",
      "        [-0.6408, -0.2203,  0.2717,  ...,  0.2819, -0.4768,  0.6358],\n",
      "        [-0.6653, -0.4650, -0.8485,  ..., -0.6275, -0.6010,  0.8538]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6879, -0.0673,  0.3225,  ...,  0.1957, -0.4102,  0.7560],\n",
      "        [-0.6054, -0.5953, -0.9639,  ..., -0.8908, -0.6758,  0.4818],\n",
      "        [-0.7752, -0.4886, -0.8183,  ..., -0.6264, -0.6962,  0.7857],\n",
      "        ...,\n",
      "        [-0.5951, -0.4199, -0.9825,  ..., -0.8953, -0.5304,  0.5060],\n",
      "        [-0.6300, -0.7156, -0.9963,  ..., -0.9903, -0.6781,  0.7031],\n",
      "        [-0.7642, -0.3347, -0.4071,  ..., -0.4005, -0.6330,  0.8534]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6703, -0.3184, -0.6619,  ..., -0.4321, -0.6082,  0.5942],\n",
      "        [-0.7399, -0.2396, -0.5697,  ..., -0.2057, -0.5927,  0.7982],\n",
      "        [-0.6993, -0.3713, -0.8198,  ..., -0.7036, -0.5293,  0.8391],\n",
      "        ...,\n",
      "        [-0.7659, -0.4900, -0.9184,  ..., -0.7225, -0.7045,  0.7697],\n",
      "        [-0.8980, -0.5803, -0.9871,  ..., -0.9367, -0.5798,  0.8080],\n",
      "        [-0.6487, -0.3954, -0.7804,  ..., -0.5913, -0.5736,  0.7310]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7431, -0.3315, -0.8261,  ..., -0.5966, -0.5617,  0.7452],\n",
      "        [-0.5964, -0.0772, -0.4637,  ..., -0.4104, -0.5441,  0.5870],\n",
      "        [-0.8569, -0.2587, -0.7973,  ..., -0.6797, -0.6225,  0.8514],\n",
      "        ...,\n",
      "        [-0.6412, -0.4698, -0.8651,  ..., -0.6440, -0.6141,  0.8021],\n",
      "        [-0.8945, -0.5677, -0.9343,  ..., -0.7864, -0.7574,  0.9275],\n",
      "        [-0.6289, -0.4157, -0.8601,  ..., -0.7079, -0.5752,  0.7275]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8732, -0.2028,  0.2517,  ...,  0.1364, -0.5575,  0.9104],\n",
      "        [-0.8266, -0.2254, -0.6811,  ..., -0.5916, -0.7200,  0.8323],\n",
      "        [-0.8884, -0.6896, -0.9949,  ..., -0.9478, -0.7520,  0.6448],\n",
      "        ...,\n",
      "        [-0.5896, -0.2365, -0.8342,  ..., -0.7445, -0.4845,  0.6590],\n",
      "        [-0.8690, -0.3186, -0.5176,  ...,  0.0097, -0.6599,  0.9202],\n",
      "        [-0.6584, -0.5795, -0.9536,  ..., -0.8709, -0.6586,  0.8128]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8792, -0.3555, -0.9408,  ..., -0.7433, -0.6744,  0.9362],\n",
      "        [-0.8475, -0.4962, -0.9410,  ..., -0.8225, -0.6078,  0.9055],\n",
      "        [-0.6987, -0.3057, -0.6242,  ..., -0.5538, -0.5009,  0.8244],\n",
      "        ...,\n",
      "        [-0.7320, -0.1661, -0.8391,  ..., -0.6889, -0.4596,  0.8690],\n",
      "        [-0.8836, -0.5383, -0.9858,  ..., -0.8982, -0.7378,  0.9267],\n",
      "        [-0.7340, -0.3930, -0.9576,  ..., -0.8555, -0.6604,  0.8300]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6072, -0.2523, -0.7473,  ..., -0.5311, -0.5337,  0.7709],\n",
      "        [-0.9084, -0.5825, -0.9934,  ..., -0.9499, -0.7889,  0.9278],\n",
      "        [-0.6628, -0.3982, -0.8754,  ..., -0.7309, -0.6234,  0.8069],\n",
      "        ...,\n",
      "        [-0.7656, -0.2341, -0.2258,  ...,  0.2198, -0.5591,  0.8457],\n",
      "        [-0.6761, -0.3916, -0.9637,  ..., -0.8813, -0.5770,  0.7124],\n",
      "        [-0.8225, -0.3297, -0.7637,  ..., -0.6437, -0.5883,  0.8476]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.9181, -0.4135, -0.5982,  ..., -0.2658, -0.7339,  0.9488],\n",
      "        [-0.8022, -0.2687,  0.1764,  ...,  0.0700, -0.5025,  0.8222],\n",
      "        [-0.7742, -0.5025, -0.8593,  ..., -0.5832, -0.7102,  0.7371],\n",
      "        ...,\n",
      "        [-0.9617, -0.5070, -0.7770,  ..., -0.4890, -0.6576,  0.9672],\n",
      "        [-0.7858, -0.4380, -0.7703,  ..., -0.6181, -0.6397,  0.8590],\n",
      "        [-0.7635, -0.4025, -0.8774,  ..., -0.6323, -0.6625,  0.8141]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.9176, -0.3551, -0.5716,  ..., -0.6552, -0.6767,  0.9272],\n",
      "        [-0.7839, -0.1485,  0.2223,  ...,  0.0708, -0.5045,  0.8172],\n",
      "        [-0.8421, -0.3560, -0.5925,  ...,  0.0668, -0.6371,  0.8411],\n",
      "        ...,\n",
      "        [-0.5153, -0.5351, -0.9810,  ..., -0.9380, -0.5129,  0.5778],\n",
      "        [-0.7518, -0.5417, -0.9295,  ..., -0.7985, -0.5805,  0.4313],\n",
      "        [-0.7423, -0.3175, -0.8320,  ..., -0.8315, -0.4267,  0.8418]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7932, -0.2804, -0.7389,  ..., -0.7292, -0.5391,  0.8478],\n",
      "        [-0.8867, -0.2384, -0.8326,  ..., -0.8920, -0.6229,  0.8746],\n",
      "        [-0.8032, -0.1530,  0.1451,  ...,  0.2432, -0.5615,  0.8702],\n",
      "        ...,\n",
      "        [-0.7732, -0.3148, -0.4655,  ..., -0.3395, -0.5941,  0.8354],\n",
      "        [-0.5968, -0.4382, -0.9561,  ..., -0.8653, -0.6184,  0.6317],\n",
      "        [-0.7164, -0.5703, -0.9684,  ..., -0.9188, -0.5175,  0.6614]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8471, -0.4135, -0.9365,  ..., -0.8644, -0.5743,  0.8512],\n",
      "        [-0.6471, -0.4431, -0.7084,  ..., -0.4363, -0.6523,  0.6849],\n",
      "        [-0.9236, -0.1624,  0.8688,  ...,  0.7084, -0.4805,  0.8969],\n",
      "        ...,\n",
      "        [-0.8523, -0.2692,  0.1136,  ...,  0.0383, -0.5182,  0.7932],\n",
      "        [-0.8937, -0.5036, -0.8220,  ..., -0.2209, -0.7800,  0.8982],\n",
      "        [-0.5755, -0.1234, -0.0757,  ..., -0.1384, -0.5718,  0.6262]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3828, -0.5259, -0.9754,  ..., -0.8262, -0.6765,  0.2346],\n",
      "        [-0.7755, -0.4821, -0.6422,  ..., -0.3501, -0.4883,  0.8145],\n",
      "        [-0.4577, -0.1750, -0.6040,  ..., -0.5679, -0.5457,  0.7749],\n",
      "        ...,\n",
      "        [-0.7544, -0.5168, -0.9646,  ..., -0.9130, -0.6038,  0.5666],\n",
      "        [-0.4613, -0.4301, -0.9588,  ..., -0.8994, -0.4831,  0.7379],\n",
      "        [-0.6369, -0.4937, -0.9708,  ..., -0.8124, -0.6690,  0.5974]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.5788, -0.4803, -0.9056,  ..., -0.6426, -0.6064,  0.5610],\n",
      "        [-0.4452, -0.5909, -0.9885,  ..., -0.9771, -0.6305,  0.5047],\n",
      "        [-0.8260, -0.4377, -0.8205,  ..., -0.4184, -0.6957,  0.8403],\n",
      "        ...,\n",
      "        [-0.7805, -0.2409,  0.3211,  ...,  0.3028, -0.4868,  0.8323],\n",
      "        [-0.8432, -0.4414, -0.8997,  ..., -0.5789, -0.7413,  0.7481],\n",
      "        [-0.5530, -0.4981, -0.9822,  ..., -0.9696, -0.6187,  0.6843]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7013, -0.3171, -0.6444,  ..., -0.5887, -0.5959,  0.6978],\n",
      "        [-0.8219, -0.1767, -0.8582,  ..., -0.7854, -0.5452,  0.8790],\n",
      "        [-0.5863, -0.2390, -0.4218,  ..., -0.5564, -0.5360,  0.6469],\n",
      "        ...,\n",
      "        [-0.6340, -0.4643, -0.9852,  ..., -0.8981, -0.4850,  0.4592],\n",
      "        [-0.6158, -0.2016, -0.3457,  ..., -0.3969, -0.4555,  0.7422],\n",
      "        [-0.4662, -0.4478, -0.6852,  ..., -0.4846, -0.5676,  0.7767]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7003, -0.2845, -0.4455,  ..., -0.1277, -0.5795,  0.7966],\n",
      "        [-0.7663, -0.2953, -0.8147,  ..., -0.7412, -0.5944,  0.8282],\n",
      "        [-0.7102, -0.1373,  0.7161,  ...,  0.6145, -0.5384,  0.7946],\n",
      "        ...,\n",
      "        [-0.8403, -0.2538, -0.6327,  ..., -0.4866, -0.5733,  0.8832],\n",
      "        [-0.8813, -0.3906, -0.8156,  ..., -0.6136, -0.6643,  0.8257],\n",
      "        [-0.8396, -0.3184, -0.8268,  ..., -0.7926, -0.4935,  0.7900]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8965, -0.2672, -0.7940,  ..., -0.8224, -0.5961,  0.8724],\n",
      "        [-0.6919, -0.2624, -0.3712,  ..., -0.2109, -0.5066,  0.7664],\n",
      "        [-0.6286, -0.3345, -0.8288,  ..., -0.8055, -0.5855,  0.7603],\n",
      "        ...,\n",
      "        [-0.8186, -0.3250, -0.7092,  ..., -0.4516, -0.5685,  0.7939],\n",
      "        [-0.8794, -0.2584, -0.7286,  ..., -0.7680, -0.5828,  0.8946],\n",
      "        [-0.7527, -0.4290, -0.6825,  ..., -0.3909, -0.7061,  0.7857]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.9686, -0.5568, -0.7966,  ..., -0.6878, -0.6922,  0.9648],\n",
      "        [-0.8448, -0.2652, -0.5993,  ..., -0.3399, -0.6436,  0.8240],\n",
      "        [-0.5833, -0.5926, -0.9924,  ..., -0.9895, -0.7217,  0.5104],\n",
      "        ...,\n",
      "        [-0.8180, -0.1852, -0.4536,  ..., -0.0912, -0.6390,  0.8649],\n",
      "        [-0.5573, -0.4332, -0.9689,  ..., -0.9078, -0.5467,  0.4338],\n",
      "        [-0.5908, -0.2206, -0.6039,  ..., -0.6572, -0.4799,  0.5543]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8596, -0.3251, -0.9786,  ..., -0.9110, -0.6932,  0.8768],\n",
      "        [-0.5795, -0.2321, -0.4335,  ..., -0.0835, -0.4649,  0.4793],\n",
      "        [-0.7504, -0.1371, -0.7756,  ..., -0.7804, -0.1966,  0.6740],\n",
      "        ...,\n",
      "        [-0.9166, -0.5182, -0.8899,  ..., -0.8440, -0.7210,  0.9464],\n",
      "        [-0.9062, -0.4458, -0.9033,  ..., -0.8160, -0.6399,  0.9319],\n",
      "        [-0.6268, -0.1997, -0.2406,  ..., -0.1768, -0.5718,  0.7986]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8473, -0.4313, -0.8540,  ..., -0.6508, -0.6775,  0.8272],\n",
      "        [-0.6425, -0.1126,  0.6854,  ...,  0.3772, -0.4638,  0.7162],\n",
      "        [-0.9003, -0.5183, -0.5786,  ..., -0.4646, -0.6198,  0.9079],\n",
      "        ...,\n",
      "        [-0.8092, -0.1705, -0.4059,  ..., -0.5170, -0.4940,  0.6510],\n",
      "        [-0.7345, -0.4543, -0.9684,  ..., -0.9024, -0.5168,  0.7229],\n",
      "        [-0.6830, -0.5052, -0.9516,  ..., -0.8320, -0.7027,  0.7557]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6330, -0.4027, -0.9623,  ..., -0.7976, -0.6296,  0.5822],\n",
      "        [-0.6431, -0.2945, -0.8693,  ..., -0.6968, -0.4198,  0.7467],\n",
      "        [-0.8108, -0.3390, -0.5556,  ..., -0.1935, -0.5717,  0.8503],\n",
      "        ...,\n",
      "        [-0.4425, -0.1541, -0.4943,  ..., -0.4090, -0.5326,  0.7107],\n",
      "        [-0.6578, -0.2105, -0.8061,  ..., -0.6459, -0.5615,  0.7316],\n",
      "        [-0.5737, -0.4801, -0.9628,  ..., -0.8453, -0.7206,  0.7363]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7290, -0.1602,  0.5445,  ...,  0.3452, -0.5055,  0.8009],\n",
      "        [-0.9364, -0.5601, -0.9440,  ..., -0.7472, -0.8068,  0.9477],\n",
      "        [-0.8972, -0.3346, -0.5972,  ..., -0.4165, -0.6256,  0.9135],\n",
      "        ...,\n",
      "        [-0.8488, -0.4333, -0.6777,  ..., -0.5335, -0.6197,  0.8193],\n",
      "        [-0.8040, -0.6116, -0.9749,  ..., -0.9437, -0.6891,  0.8597],\n",
      "        [-0.8607, -0.3698, -0.8470,  ..., -0.5572, -0.5395,  0.9009]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7717, -0.4917, -0.9827,  ..., -0.9354, -0.6736,  0.8159],\n",
      "        [-0.7787, -0.4321, -0.6328,  ..., -0.5441, -0.5749,  0.8458],\n",
      "        [-0.8977, -0.3076, -0.4991,  ..., -0.2259, -0.5913,  0.9231],\n",
      "        ...,\n",
      "        [-0.7192, -0.1998, -0.5132,  ..., -0.3972, -0.4804,  0.8001],\n",
      "        [-0.7584, -0.5424, -0.9595,  ..., -0.9512, -0.6196,  0.7380],\n",
      "        [-0.8818, -0.4730, -0.5778,  ..., -0.3216, -0.7588,  0.9161]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6494, -0.5297, -0.9444,  ..., -0.6898, -0.5859,  0.7304],\n",
      "        [-0.6615, -0.6812, -0.9917,  ..., -0.9514, -0.7307,  0.7808],\n",
      "        [-0.7444, -0.4657, -0.9439,  ..., -0.8493, -0.7131,  0.5615],\n",
      "        ...,\n",
      "        [-0.8193, -0.2005, -0.6626,  ..., -0.4860, -0.5305,  0.7943],\n",
      "        [-0.7403, -0.4759, -0.8145,  ..., -0.6764, -0.5670,  0.7267],\n",
      "        [-0.5243, -0.3245, -0.9058,  ..., -0.8457, -0.4097,  0.3406]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7228, -0.1751,  0.3131,  ..., -0.0071, -0.4521,  0.7650],\n",
      "        [-0.8107, -0.3922, -0.9419,  ..., -0.7280, -0.5687,  0.8432],\n",
      "        [-0.7969, -0.3506, -0.7956,  ..., -0.7248, -0.6438,  0.9016],\n",
      "        ...,\n",
      "        [-0.9031, -0.3361, -0.4958,  ..., -0.3498, -0.5809,  0.8978],\n",
      "        [-0.9403, -0.7058, -0.9416,  ..., -0.7349, -0.8284,  0.9400],\n",
      "        [-0.9378, -0.4590, -0.3316,  ..., -0.1610, -0.6210,  0.9347]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.4963, -0.3485, -0.8237,  ..., -0.5745, -0.6032,  0.5200],\n",
      "        [-0.6921, -0.2560, -0.4327,  ..., -0.1192, -0.5871,  0.6803],\n",
      "        [-0.7037, -0.3283, -0.6827,  ..., -0.5300, -0.5473,  0.7202],\n",
      "        ...,\n",
      "        [-0.7840, -0.4639, -0.9263,  ..., -0.8798, -0.6538,  0.8723],\n",
      "        [-0.7672, -0.4931, -0.9807,  ..., -0.9502, -0.4998,  0.8299],\n",
      "        [-0.7264, -0.3653, -0.6646,  ..., -0.4019, -0.6267,  0.8408]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7911, -0.4224, -0.7938,  ..., -0.6123, -0.6178,  0.8783],\n",
      "        [-0.8178, -0.1981, -0.2938,  ..., -0.1725, -0.5310,  0.8300],\n",
      "        [-0.9576, -0.3562, -0.0578,  ..., -0.4721, -0.6229,  0.9444],\n",
      "        ...,\n",
      "        [-0.4862, -0.3716, -0.5626,  ..., -0.4570, -0.5723,  0.6674],\n",
      "        [-0.4865, -0.0740,  0.5761,  ...,  0.1794, -0.4419,  0.7044],\n",
      "        [-0.8021, -0.5294, -0.9640,  ..., -0.8742, -0.7103,  0.7597]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.5731, -0.2140, -0.5113,  ..., -0.2460, -0.5508,  0.7397],\n",
      "        [-0.7036, -0.2846, -0.6806,  ..., -0.4329, -0.5305,  0.8698],\n",
      "        [-0.6590, -0.4648, -0.9402,  ..., -0.6620, -0.6376,  0.6503],\n",
      "        ...,\n",
      "        [-0.6962, -0.6423, -0.9644,  ..., -0.8460, -0.7478,  0.7842],\n",
      "        [-0.2095, -0.5865, -0.9379,  ..., -0.8570, -0.5758,  0.6179],\n",
      "        [-0.6138, -0.4704, -0.8965,  ..., -0.7885, -0.6757,  0.8162]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7572, -0.1033, -0.0535,  ...,  0.1313, -0.5311,  0.8868],\n",
      "        [-0.3950, -0.4707, -0.8878,  ..., -0.6016, -0.6313,  0.3854],\n",
      "        [-0.8735, -0.4482, -0.8241,  ..., -0.7569, -0.5653,  0.9081],\n",
      "        ...,\n",
      "        [-0.3033,  0.2173,  0.9797,  ...,  0.8893, -0.1692,  0.4582],\n",
      "        [-0.3694, -0.3747, -0.9118,  ..., -0.8054, -0.5039,  0.4885],\n",
      "        [-0.5452, -0.5056, -0.9729,  ..., -0.9515, -0.5827,  0.3777]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8820, -0.3806, -0.7350,  ..., -0.3835, -0.7236,  0.8873],\n",
      "        [-0.5265, -0.4220, -0.9156,  ..., -0.8319, -0.5483,  0.6518],\n",
      "        [-0.9572, -0.0697,  0.4406,  ...,  0.0866, -0.5657,  0.9620],\n",
      "        ...,\n",
      "        [-0.7054, -0.3616, -0.3139,  ...,  0.3652, -0.6938,  0.7738],\n",
      "        [-0.6507, -0.5648, -0.8587,  ..., -0.6231, -0.6325,  0.7083],\n",
      "        [-0.8171, -0.5516, -0.9422,  ..., -0.8645, -0.7426,  0.8490]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8180, -0.3439, -0.8573,  ..., -0.5955, -0.6428,  0.8955],\n",
      "        [-0.8604, -0.4062, -0.9459,  ..., -0.8537, -0.6865,  0.8150],\n",
      "        [-0.7234, -0.2384, -0.7770,  ..., -0.4849, -0.5324,  0.8045],\n",
      "        ...,\n",
      "        [-0.6927, -0.3051, -0.7282,  ..., -0.4776, -0.6250,  0.7156],\n",
      "        [-0.5747, -0.5464, -0.9859,  ..., -0.9140, -0.5929,  0.5666],\n",
      "        [-0.9024, -0.4729, -0.9395,  ..., -0.8106, -0.7181,  0.8841]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3427, -0.2272, -0.7703,  ..., -0.6857, -0.5067,  0.7097],\n",
      "        [-0.6564, -0.2556, -0.3082,  ..., -0.2707, -0.5303,  0.8116],\n",
      "        [-0.8064, -0.4476, -0.8131,  ..., -0.8021, -0.5483,  0.7242],\n",
      "        ...,\n",
      "        [-0.6005, -0.5275, -0.9238,  ..., -0.6472, -0.6613,  0.6733],\n",
      "        [-0.7316, -0.3046, -0.6859,  ..., -0.4546, -0.5684,  0.8030],\n",
      "        [-0.9272, -0.4652, -0.9735,  ..., -0.8574, -0.7304,  0.8806]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6616, -0.5359, -0.9428,  ..., -0.8374, -0.6227,  0.6737],\n",
      "        [-0.7250, -0.4179, -0.9065,  ..., -0.7455, -0.5873,  0.8246],\n",
      "        [-0.8569, -0.4236, -0.4863,  ...,  0.0486, -0.6869,  0.8994],\n",
      "        ...,\n",
      "        [-0.6527, -0.3883, -0.5386,  ..., -0.4090, -0.6128,  0.5467],\n",
      "        [-0.8500, -0.2793, -0.6702,  ..., -0.3877, -0.6133,  0.8550],\n",
      "        [-0.6713, -0.3034, -0.5688,  ..., -0.3950, -0.3728,  0.4772]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7492, -0.3636, -0.8476,  ..., -0.5024, -0.6597,  0.7061],\n",
      "        [-0.8205, -0.3283, -0.4182,  ...,  0.0854, -0.6631,  0.8506],\n",
      "        [-0.8726, -0.2117, -0.1691,  ..., -0.3643, -0.5183,  0.9084],\n",
      "        ...,\n",
      "        [-0.8783, -0.3771, -0.8646,  ..., -0.8541, -0.7079,  0.9087],\n",
      "        [-0.7416, -0.2077, -0.5775,  ..., -0.3092, -0.5608,  0.7841],\n",
      "        [-0.7109, -0.1775,  0.6307,  ...,  0.5347, -0.5650,  0.7887]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7408, -0.3278, -0.8560,  ..., -0.7252, -0.6678,  0.7691],\n",
      "        [-0.8053, -0.3903, -0.4879,  ..., -0.5441, -0.6092,  0.8813],\n",
      "        [-0.6085, -0.3501, -0.9654,  ..., -0.8340, -0.4782,  0.5415],\n",
      "        ...,\n",
      "        [-0.5820, -0.1240, -0.2333,  ..., -0.3795, -0.4104,  0.7345],\n",
      "        [-0.8542, -0.4313, -0.7386,  ..., -0.6329, -0.6886,  0.9017],\n",
      "        [-0.7102, -0.4837, -0.8841,  ..., -0.5872, -0.7502,  0.6259]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8123, -0.5726, -0.8545,  ..., -0.8083, -0.7224,  0.9136],\n",
      "        [-0.6797, -0.1937, -0.1292,  ...,  0.1187, -0.6410,  0.8050],\n",
      "        [-0.7764, -0.5671, -0.9313,  ..., -0.9395, -0.7683,  0.7962],\n",
      "        ...,\n",
      "        [-0.7435, -0.4342, -0.7775,  ..., -0.6636, -0.6194,  0.7324],\n",
      "        [-0.7221, -0.3788, -0.8293,  ..., -0.4465, -0.6642,  0.8176],\n",
      "        [-0.7951, -0.5630, -0.9808,  ..., -0.9086, -0.6628,  0.5377]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7408, -0.4381, -0.8792,  ..., -0.3586, -0.7011,  0.8393],\n",
      "        [-0.3982,  0.0307,  0.6890,  ...,  0.1999, -0.4207,  0.4356],\n",
      "        [-0.7107, -0.4709, -0.7697,  ..., -0.4921, -0.7035,  0.7540],\n",
      "        ...,\n",
      "        [-0.8538, -0.3478, -0.8523,  ..., -0.6492, -0.5645,  0.8608],\n",
      "        [-0.8319, -0.3631, -0.6594,  ..., -0.3920, -0.6364,  0.8701],\n",
      "        [-0.5357, -0.4534, -0.9796,  ..., -0.9290, -0.5321,  0.7995]],\n",
      "       device='cuda:0')\n",
      "tensor([[-6.8971e-01, -2.7339e-01, -8.2652e-01,  ..., -6.1305e-01,\n",
      "         -4.7429e-01,  7.4787e-01],\n",
      "        [-9.0201e-01, -6.5358e-01, -9.8603e-01,  ..., -9.5713e-01,\n",
      "         -7.5775e-01,  8.8761e-01],\n",
      "        [-6.3430e-01, -2.3736e-01, -9.7238e-01,  ..., -9.6843e-01,\n",
      "         -3.5968e-01,  6.7389e-01],\n",
      "        ...,\n",
      "        [-7.2934e-01, -3.2092e-01, -8.9298e-01,  ..., -8.9233e-01,\n",
      "         -6.3434e-01,  3.9203e-01],\n",
      "        [-1.8806e-01,  1.9732e-02,  7.4315e-01,  ...,  5.9582e-01,\n",
      "         -2.1245e-01,  9.2802e-04],\n",
      "        [-7.8430e-01, -4.2963e-01, -7.0785e-01,  ..., -6.1396e-01,\n",
      "         -6.1030e-01,  8.5971e-01]], device='cuda:0')\n",
      "tensor([[-0.9780, -0.5379, -0.6875,  ..., -0.6348, -0.7166,  0.9700],\n",
      "        [-0.7401, -0.1920, -0.4822,  ..., -0.5627, -0.6216,  0.8056],\n",
      "        [-0.8423, -0.2395, -0.7194,  ..., -0.3754, -0.4964,  0.8194],\n",
      "        ...,\n",
      "        [-0.5601, -0.4860, -0.9027,  ..., -0.8631, -0.6717,  0.5941],\n",
      "        [-0.3203, -0.5671, -0.9835,  ..., -0.9478, -0.6087,  0.4289],\n",
      "        [-0.8357, -0.4321, -0.8971,  ..., -0.7840, -0.6619,  0.8770]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6821, -0.2655, -0.4897,  ..., -0.0555, -0.5466,  0.8122],\n",
      "        [-0.8219, -0.5005, -0.9537,  ..., -0.9582, -0.5840,  0.7588],\n",
      "        [-0.7402, -0.5195, -0.8909,  ..., -0.6703, -0.6421,  0.7928],\n",
      "        ...,\n",
      "        [-0.7624, -0.5675, -0.9213,  ..., -0.7673, -0.7361,  0.7534],\n",
      "        [-0.8656, -0.2888, -0.5733,  ..., -0.5689, -0.6486,  0.9490],\n",
      "        [-0.5487, -0.2126, -0.3565,  ..., -0.0729, -0.4797,  0.7854]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8311, -0.5398, -0.9791,  ..., -0.9035, -0.6446,  0.7776],\n",
      "        [-0.2127, -0.0209,  0.0211,  ..., -0.1958, -0.2345,  0.5681],\n",
      "        [-0.6708, -0.3275, -0.8704,  ..., -0.6244, -0.5036,  0.7668],\n",
      "        ...,\n",
      "        [-0.7087, -0.2651, -0.8708,  ..., -0.7449, -0.6080,  0.7826],\n",
      "        [-0.9270, -0.4962, -0.9564,  ..., -0.8541, -0.7066,  0.9073],\n",
      "        [-0.8078, -0.4551, -0.9659,  ..., -0.8433, -0.6395,  0.8196]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-460170d22dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a8875e82e2a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# get model predictions for the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# compute the loss between actual and predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/e36t11/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-01d273b566bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/e36t11/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/e36t11/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/e36t11/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/e36t11/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/e36t11/lib/python3.6/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# number of training epochs\n",
    "epochs = 5\n",
    "\n",
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        model_path = os.path.join(models_dir, 'saved_weights.pt')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py36 (torch)",
   "language": "python",
   "name": "e36t11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
